{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyunjin-lee-2002/Chapter01/blob/master/6_(colab)%E1%84%8B%E1%85%B5%E1%84%86%E1%85%B5%E1%84%8C%E1%85%B5_%E1%84%87%E1%85%AE%E1%86%AB%E1%84%85%E1%85%B2_%E1%84%86%E1%85%A9%E1%84%83%E1%85%A6%E1%86%AF_%E1%84%92%E1%85%A1%E1%86%A8%E1%84%89%E1%85%B3%E1%86%B8%E1%84%89%E1%85%B5%E1%84%8F%E1%85%B5%E1%84%80%E1%85%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "990167ab",
      "metadata": {
        "id": "990167ab"
      },
      "source": [
        "## ğŸ§  PyTorch CNN ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµì‹œí‚¤ê¸°\n",
        "\n",
        "Fashion MNIST ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ ê³¼ì •ì€ **ë°ì´í„° ì¤€ë¹„**, **ëª¨ë¸ ì •ì˜**, **í•™ìŠµ ì„¤ì •**, ê·¸ë¦¬ê³  **í•™ìŠµ ë° í‰ê°€ ë£¨í”„**ì˜ ë„¤ ë‹¨ê³„ë¡œ ìš”ì•½ë©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f00a37da",
      "metadata": {
        "id": "f00a37da"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import v2\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8611311b",
      "metadata": {
        "id": "8611311b"
      },
      "source": [
        "## 1. ë°ì´í„° ì¤€ë¹„ ë° ë¶„í• \n",
        "\n",
        "ëª¨ë¸ í•™ìŠµì„ ìœ„í•´ ê¸°ì¡´ì˜ Fashion MNIST ë°ì´í„°ë¥¼ í•™ìŠµ, ê²€ì¦, í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ë‚˜ëˆ„ê³  ì „ì²˜ë¦¬ë¥¼ ì ìš©í•©ë‹ˆë‹¤.\n",
        "\n",
        "### ë°ì´í„°ì…‹ ë¶„í• \n",
        "\n",
        "* **`random_split`**:\n",
        "\n",
        "    - ì´ˆê¸° **í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹(10,000ê°œ)** ì„ `random_split` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ **ê²€ì¦ ë°ì´í„°ì…‹ (5,000ê°œ)** ê³¼ **ìµœì¢… í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ (5,000ê°œ)** ìœ¼ë¡œ ë¶„í• í–ˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "* **Transform ì ìš©**:\n",
        "\n",
        "    * **í•™ìŠµ ë°ì´í„° (`transforms_train`)** :\n",
        "\n",
        "        - **ì´ë¯¸ì§€ ì¦ê°•**(`RandomHorizontalFlip`, `RandomResizedCrop`, `RandomRotation`)ê³¼ **ì „ì²˜ë¦¬**(`ToImage`, `ToDtype(0~1 ìŠ¤ì¼€ì¼ë§)`, `Normalize`)ë¥¼ ëª¨ë‘ ì ìš©í–ˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "    * **ê²€ì¦/í…ŒìŠ¤íŠ¸ ë°ì´í„° (`transforms_test`)**\n",
        "\n",
        "        - **ì´ë¯¸ì§€ ì¦ê°•ì„ ì œì™¸**í•˜ê³  **ì „ì²˜ë¦¬**ë§Œ ì ìš©í–ˆìŠµë‹ˆë‹¤.\n",
        "    \n",
        "* **`DataLoader`**:\n",
        "\n",
        "    - ë°°ì¹˜ í¬ê¸° 128 (Train, `shuffle=True`, `drop_last=True`)ê³¼ 32 (Validation/Test)ë¡œ ì„¤ì •í•˜ì—¬ ë°ì´í„°ë¥¼ ëª¨ë¸ì— ê³µê¸‰í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "cb442336",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb442336",
        "outputId": "f3a76b75-3bdf-42bb-8d9d-4b287a9ab944"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26.4M/26.4M [00:01<00:00, 13.4MB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29.5k/29.5k [00:00<00:00, 211kB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.42M/4.42M [00:01<00:00, 3.95MB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.15k/5.15k [00:00<00:00, 11.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "# =============================================================================\n",
        "# ë°ì´í„° ì¤€ë¹„ (ì „ì²˜ë¦¬, ì¦ê°•, ë°ì´í„°ë¡œë”)\n",
        "# =============================================================================\n",
        "\n",
        "# 1-1. ì „ì²˜ë¦¬ ë° ë°ì´í„° ì¦ê°• ì •ì˜\n",
        "# í•™ìŠµ ë°ì´í„°ì—ëŠ” ì´ë¯¸ì§€ ì¦ê°•(Augmentation)ì„ í¬í•¨í•˜ì—¬ ëª¨ë¸ì˜ ì¼ë°˜í™” ì„±ëŠ¥ì„ ë†’ì…ë‹ˆë‹¤.\n",
        "transforms_train = v2.Compose(\n",
        "    [\n",
        "        v2.ToImage(),                          # PIL Imageë¥¼ PyTorch í…ì„œë¡œ ë³€í™˜\n",
        "        v2.RandomHorizontalFlip(),             # ë¬´ì‘ìœ„ ì¢Œìš° ë°˜ì „ (ì¦ê°•)\n",
        "        v2.RandomResizedCrop(size=28),         # ë¬´ì‘ìœ„ë¡œ ì˜ë¼ì„œ 28x28ë¡œ ë¦¬ì‚¬ì´ì¦ˆ (ì¦ê°•)\n",
        "        v2.RandomRotation(degrees=10),         # ë¬´ì‘ìœ„ íšŒì „ (ì¦ê°•)\n",
        "        v2.ToDtype(dtype=torch.float32, scale=True), # í”½ì…€ ê°’ì„ 0~1 ë²”ìœ„ì˜ float íƒ€ì…ìœ¼ë¡œ ìŠ¤ì¼€ì¼ë§\n",
        "        v2.Normalize(mean=[0.286], std=[0.353]), # í•™ìŠµ ë°ì´í„°ì˜ í‰ê· /í‘œì¤€í¸ì°¨ë¥¼ ì´ìš©í•´ í‘œì¤€í™” (Normalize)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# í…ŒìŠ¤íŠ¸/ê²€ì¦ ë°ì´í„°ì—ëŠ” ì¦ê°•ì„ ì œì™¸í•˜ê³  í•„ìˆ˜ì ì¸ ì „ì²˜ë¦¬ë§Œ ì ìš©í•©ë‹ˆë‹¤.\n",
        "transforms_test = v2.Compose(\n",
        "    [\n",
        "        v2.ToImage(),                          # PIL Imageë¥¼ PyTorch í…ì„œë¡œ ë³€í™˜\n",
        "        v2.ToDtype(dtype=torch.float32, scale=True), # í”½ì…€ ê°’ì„ 0~1 ë²”ìœ„ì˜ float íƒ€ì…ìœ¼ë¡œ ìŠ¤ì¼€ì¼ë§\n",
        "        v2.Normalize(mean=[0.286], std=[0.353]), # í‘œì¤€í™”\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 1-2. FashionMNIST ë°ì´í„°ì…‹ ë¡œë“œ\n",
        "train_dataset = datasets.FashionMNIST(\n",
        "    root='./fashion_mnist',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transforms_train,  # í•™ìŠµ ë°ì´í„°ì— ì¦ê°•/ì „ì²˜ë¦¬ ì ìš©\n",
        ")\n",
        "\n",
        "test_dataset_full = datasets.FashionMNIST(\n",
        "    root='./fashion_mnist',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transforms_test,   # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ëŠ” ì „ì²˜ë¦¬ë§Œ ì ìš©\n",
        ")\n",
        "\n",
        "# 1-3. í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì„ ê²€ì¦(Validation)ê³¼ ìµœì¢… í…ŒìŠ¤íŠ¸(Test)ë¡œ ë¶„í• \n",
        "# ë§Œ ê°œì˜ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤‘ 5000ê°œë¥¼ ê²€ì¦ìš©ìœ¼ë¡œ, ë‚˜ë¨¸ì§€ 5000ê°œë¥¼ ìµœì¢… í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ë¶„í• \n",
        "val_dataset, test_dataset = random_split(test_dataset_full, [5000, 5000])\n",
        "\n",
        "# 1-4. DataLoader ê°ì²´ ìƒì„±\n",
        "train_dataloader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=128,\n",
        "    shuffle=True,          # í•™ìŠµ ì‹œ ë°ì´í„° ìˆœì„œë¥¼ ì„ìŒ\n",
        "    drop_last=True         # ë§ˆì§€ë§‰ ë°°ì¹˜ë¥¼ ë²„ë ¤ ë°°ì¹˜ í¬ê¸°ë¥¼ ì¼ì •í•˜ê²Œ ìœ ì§€\n",
        ")\n",
        "val_dataloader = DataLoader(dataset=val_dataset, batch_size=32)\n",
        "test_dataloader = DataLoader(dataset=test_dataset, batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61d18cb9",
      "metadata": {
        "id": "61d18cb9"
      },
      "source": [
        "\n",
        "## 2. ëª¨ë¸ ë° í•™ìŠµ í™˜ê²½ ì„¤ì •\n",
        "\n",
        "### ëª¨ë¸ êµ¬ì¡° (`CNNModel`)\n",
        "\n",
        "* **CNN ë¸”ë¡**: ë‘ ê°œì˜ `Conv2d` ë ˆì´ì–´ì™€ `MaxPool2d` ë ˆì´ì–´ë¥¼ ì¡°í•©í–ˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "    * `Conv2d(1, 32, ...)`ì™€ `Conv2d(32, 64, ...)`ë¡œ ì±„ë„ ìˆ˜ë¥¼ ì¦ê°€ì‹œì¼°ìŠµë‹ˆë‹¤.\n",
        "\n",
        "    * `MaxPool2d(2, 2)`ë¥¼ ë‘ ë²ˆ ì ìš©í•˜ì—¬ íŠ¹ì§• ë§µì˜ í¬ê¸°ë¥¼ $28 \\times 28 \\to 14 \\times 14 \\to 7 \\times 7$ë¡œ ì¶•ì†Œí–ˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "* **Fully Connected**: Flatten ì§í›„ ë²¡í„° í¬ê¸°ì¸ **3136**ì„ ì²« ë²ˆì§¸ `nn.Linear` ë ˆì´ì–´ì˜ ì…ë ¥ ì°¨ì›ìœ¼ë¡œ ì •í™•íˆ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "* **Dropout**: `nn.Dropout(0.2)`ë¥¼ ì ìš©í•˜ì—¬ ì˜¤ë²„í”¼íŒ…ì„ ë°©ì§€í–ˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "### ì„¤ì •\n",
        "\n",
        "* **Loss Function**: 10ê°œ í´ë˜ìŠ¤ ë¶„ë¥˜ ë¬¸ì œì´ë¯€ë¡œ `nn.CrossEntropyLoss()`ë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "* **Optimizer**: **`optim.Adam`** ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ íŒŒë¼ë¯¸í„°ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.\n",
        "\n",
        "* **Device**: GPU(`cuda`) ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ì— ë”°ë¼ ë””ë°”ì´ìŠ¤ë¥¼ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8abc3844",
      "metadata": {
        "id": "8abc3844"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# CNN ëª¨ë¸ ì •ì˜\n",
        "# =============================================================================\n",
        "\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Conv1: 1ì±„ë„(Grayscale) ì…ë ¥ -> 32ì±„ë„ ì¶œë ¥. ì»¤ë„ 3x3, íŒ¨ë”© 1ë¡œ í¬ê¸° ìœ ì§€ (28x28 -> 28x28)\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, 1, 1)\n",
        "        # Conv2: 32ì±„ë„ ì…ë ¥ -> 64ì±„ë„ ì¶œë ¥. ì»¤ë„ 3x3, íŒ¨ë”© 1ë¡œ í¬ê¸° ìœ ì§€ (14x14 -> 14x14)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1, 1)\n",
        "        # MaxPool: 2x2 í’€ë§, ìŠ¤íŠ¸ë¼ì´ë“œ 2 (ë†’ì´/ë„ˆë¹„ 1/2 ì¶•ì†Œ)\n",
        "        self.maxpool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # í•™ìŠµ ì‹œ 20% í™•ë¥ ë¡œ ë‰´ëŸ° ë¹„í™œì„±í™” (ì˜¤ë²„í”¼íŒ… ë°©ì§€)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "        # ë‹¤ì°¨ì› í”¼ì²˜ë§µì„ 1ì°¨ì› ë²¡í„°ë¡œ í¼ì¹¨ (Linear ë ˆì´ì–´ ì…ë ¥ì„ ìœ„í•´ í•„ìš”)\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        # Linear1 ì…ë ¥ ì°¨ì›: 64 (ì±„ë„) * 7 * 7 (ìµœì¢… í”¼ì²˜ë§µ í¬ê¸°) = 3136\n",
        "        self.linear1 = nn.Linear(3136, 64)\n",
        "        # Linear2 ì¶œë ¥ ì°¨ì›: 10 (í´ë˜ìŠ¤ ê°œìˆ˜)\n",
        "        self.linear2 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # ì²« ë²ˆì§¸ Conv-ReLU-Pool ë¸”ë¡\n",
        "        x = F.relu(self.conv1(x)) # Conv2d í›„ í™œì„±í™” í•¨ìˆ˜ (í•¨ìˆ˜í˜• F.relu ì‚¬ìš©)\n",
        "        x = self.maxpool(x)       # Max Pooling (28x28 -> 14x14)\n",
        "\n",
        "        # ë‘ ë²ˆì§¸ Conv-ReLU-Pool ë¸”ë¡\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.maxpool(x)       # Max Pooling (14x14 -> 7x7)\n",
        "\n",
        "        # Dropout ì ìš© í›„ ë²¡í„°ë¡œ í¼ì¹˜ê¸°\n",
        "        x = self.dropout(x)\n",
        "        x = self.flatten(x)       # (N, 64, 7, 7) -> (N, 3136)\n",
        "\n",
        "        # ì™„ì „ ì—°ê²° ë ˆì´ì–´\n",
        "        x = F.relu(self.linear1(x))\n",
        "        output = self.linear2(x)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02e31abb",
      "metadata": {
        "id": "02e31abb",
        "outputId": "f26ca05a-715f-43e9-ed08-1070b55ac8bc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CNNModel(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (linear1): Linear(in_features=3136, out_features=64, bias=True)\n",
              "  (linear2): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# ëª¨ë¸, ì†ì‹¤ í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì € ì„¤ì •\n",
        "# =============================================================================\n",
        "\n",
        "model = CNNModel()\n",
        "\n",
        "# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸ ë° ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81da10e3",
      "metadata": {
        "id": "81da10e3"
      },
      "outputs": [],
      "source": [
        "# ì†ì‹¤ í•¨ìˆ˜: ë‹¤ì¤‘ ë¶„ë¥˜ ë¬¸ì œì— ì í•©í•œ CrossEntropyLoss ì‚¬ìš©\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "# ì˜µí‹°ë§ˆì´ì €: Adam ì‚¬ìš©\n",
        "optimizer = optim.Adam(model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b08eab89",
      "metadata": {
        "id": "b08eab89"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# í•™ìŠµ ë£¨í”„ ì‹¤í–‰\n",
        "# =============================================================================\n",
        "\n",
        "epochs = 5\n",
        "step = 0\n",
        "print(f\"Training started on device: {device}\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # ëª¨ë¸ì„ í•™ìŠµ ëª¨ë“œë¡œ ì „í™˜\n",
        "    model.train()\n",
        "    for train_batch in train_dataloader:\n",
        "        inputs = train_batch[0].to(device)\n",
        "        labels = train_batch[1].to(device)\n",
        "\n",
        "        # 1. ìˆœì „íŒŒ (Forward Pass)\n",
        "        preds = model(inputs)\n",
        "        loss = loss_fn(preds, labels)\n",
        "\n",
        "        # 2. ì—­ì „íŒŒ (Backward Pass)\n",
        "        loss.backward()            # ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°\n",
        "        optimizer.step()           # íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸\n",
        "        optimizer.zero_grad()      # ê·¸ë˜ë””ì–¸íŠ¸ ì´ˆê¸°í™”\n",
        "\n",
        "        step += 1\n",
        "        if step % 100 == 0:\n",
        "            print(f'step {step}, train loss: {loss.item():.4f}')\n",
        "\n",
        "    # ì—í­ ì¢…ë£Œ í›„ ê²€ì¦ ë°ì´í„°ë¡œ ëª¨ë¸ í‰ê°€\n",
        "    val_loss, val_acc = evaluate(val_dataloader, model, loss_fn)\n",
        "    print(f'epoch {epoch+1}/{epochs}, val loss: {val_loss:.4f}, val acc: {val_acc:.4f}\\n')\n",
        "\n",
        "print('Training finished!')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fab4ea0",
      "metadata": {
        "id": "8fab4ea0"
      },
      "source": [
        "\n",
        "## 3. í‰ê°€ í•¨ìˆ˜ (`evaluate`)\n",
        "\n",
        "í•™ìŠµ ê³¼ì •ì—ì„œ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì¸¡ì •í•˜ê¸° ìœ„í•œ í•¨ìˆ˜ì…ë‹ˆë‹¤.\n",
        "\n",
        "* **ëª¨ë“œ ì „í™˜**: **`model.eval()`** ì„ í˜¸ì¶œí•˜ì—¬ Dropoutê³¼ ê°™ì€ ë ˆì´ì–´ë¥¼ ë¹„í™œì„±í™”í•©ë‹ˆë‹¤.\n",
        "\n",
        "* **ê·¸ë˜ë””ì–¸íŠ¸ ë¹„í™œì„±í™”**: **`with torch.no_grad():`** ë¸”ë¡ ë‚´ì—ì„œ ì‹¤í–‰í•˜ì—¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ì„ ì¤„ì´ê³  ì†ë„ë¥¼ ë†’ì…ë‹ˆë‹¤.\n",
        "\n",
        "* **ì •í™•ë„ ê³„ì‚°**:\n",
        "\n",
        "    1.  `preds` í…ì„œì— `torch.argmax(dim=1)`ì„ ì ìš©í•˜ì—¬ ëª¨ë¸ì´ ì˜ˆì¸¡í•œ í´ë˜ìŠ¤ ì¸ë±ìŠ¤ë¥¼ êµ¬í•©ë‹ˆë‹¤.\n",
        "\n",
        "    2.  ì˜ˆì¸¡ ë ˆì´ë¸”ê³¼ ì‹¤ì œ ë ˆì´ë¸”ì´ ì¼ì¹˜í•˜ëŠ” ê°œìˆ˜(`(pred_labels == labels).sum()`)ë¥¼ ëˆ„ì í•˜ì—¬ ì •í™•ë„(Accuracy)ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8985b68",
      "metadata": {
        "id": "a8985b68"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# í‰ê°€ í•¨ìˆ˜ ì •ì˜\n",
        "# =============================================================================\n",
        "\n",
        "def evaluate(dataloader, model, loss_fn):\n",
        "    # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì „í™˜ (Dropout, BatchNorm ë“±ì´ ë¹„í™œì„±í™”ë¨)\n",
        "    model.eval()\n",
        "    losses = []\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # í‰ê°€ ì‹œì—ëŠ” ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°ì´ í•„ìš” ì—†ìœ¼ë¯€ë¡œ ê¸°ë¡ì„ ë” (ë©”ëª¨ë¦¬ ì ˆì•½)\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            inputs = batch[0].to(device)\n",
        "            labels = batch[1].to(device)\n",
        "\n",
        "            # 1. ì˜ˆì¸¡ê°’ ê³„ì‚°\n",
        "            preds = model(inputs)  # [ë°°ì¹˜ í¬ê¸°, í´ë˜ìŠ¤ ê°œìˆ˜]\n",
        "\n",
        "            # 2. Loss ê³„ì‚°\n",
        "            loss = loss_fn(preds, labels)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            # 3. ì •í™•ë„ ê³„ì‚°\n",
        "            # torch.argmax(dim=1)ë¡œ ê°€ì¥ ë†’ì€ ê°’ì˜ ì¸ë±ìŠ¤(ì˜ˆì¸¡ í´ë˜ìŠ¤)ë¥¼ ì¶”ì¶œ\n",
        "            pred_labels = torch.argmax(preds, dim=1)\n",
        "            # ì •ë‹µ ê°œìˆ˜ ëˆ„ì  (True: 1, False: 0ìœ¼ë¡œ ê°„ì£¼í•˜ì—¬ í•©ì‚°)\n",
        "            correct += (pred_labels == labels).sum().item()\n",
        "            total += len(preds)\n",
        "\n",
        "    # í‰ê·  Lossì™€ ì •í™•ë„ ê³„ì‚°\n",
        "    avg_loss = sum(losses) / len(losses)\n",
        "    acc = correct / total\n",
        "\n",
        "    return avg_loss, acc"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8acb68b9",
      "metadata": {
        "id": "8acb68b9"
      },
      "source": [
        "\n",
        "## 4. í•™ìŠµ ë£¨í”„ ë° ìµœì¢… í‰ê°€\n",
        "\n",
        "ê° ì—í­ë§ˆë‹¤ í•™ìŠµì„ ì§„í–‰í•˜ê³  ê²€ì¦ ë°ì´í„°ë¡œ ì„±ëŠ¥ì„ í™•ì¸í•©ë‹ˆë‹¤.\n",
        "\n",
        "1.  **ëª¨ë¸ í•™ìŠµ (`model.train()`)**:\n",
        "\n",
        "    * ë°ì´í„°ë¥¼ ëª¨ë¸ì— ì…ë ¥í•˜ì—¬ Lossë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
        "\n",
        "    * `loss.backward()`ë¡œ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ê³„ì‚°í•˜ê³ , `optimizer.step()`ìœ¼ë¡œ íŒŒë¼ë¯¸í„°ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.\n",
        "\n",
        "    * `optimizer.zero_grad()`ë¡œ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.\n",
        "\n",
        "2.  **ê²€ì¦ (`val_dataloader`)**:\n",
        "\n",
        "    * ë§¤ ì—í­ í•™ìŠµì´ ëë‚  ë•Œ, `evaluate(val_dataloader, ...)`ë¥¼ í˜¸ì¶œí•˜ì—¬ **ê²€ì¦ ì†ì‹¤ (`val loss`)** ê³¼ **ê²€ì¦ ì •í™•ë„ (`val acc`)** ë¥¼ ì¶œë ¥í•˜ê³ , ëª¨ë¸ ì„±ëŠ¥ ê°œì„  ì—¬ë¶€ë¥¼ ëª¨ë‹ˆí„°ë§í•©ë‹ˆë‹¤.\n",
        "\n",
        "3.  **ìµœì¢… í…ŒìŠ¤íŠ¸**:\n",
        "\n",
        "    * ì „ì²´ í•™ìŠµì´ ì™„ë£Œëœ í›„, `evaluate(test_dataloader, ...)`ë¥¼ í˜¸ì¶œí•˜ì—¬ **ìµœì¢… í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹** ì— ëŒ€í•œ Lossì™€ Accuracyë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2681c2df",
      "metadata": {
        "id": "2681c2df"
      },
      "outputs": [],
      "source": [
        "\n",
        "# =============================================================================\n",
        "# ìµœì¢… í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ í‰ê°€\n",
        "# =============================================================================\n",
        "\n",
        "test_loss, test_acc = evaluate(test_dataloader, model, loss_fn)\n",
        "print(f\"\\n[Final Test Result] Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "643f7269",
      "metadata": {
        "id": "643f7269"
      },
      "source": [
        "- [Colab ë…¸íŠ¸ë¶](https://colab.research.google.com/drive/1_r06QY2QhpMt_Gexafgk3qJggiG2Iap8#scrollTo=x-aa234X5ajk)ì—ì„œ í•¨ê»˜ ì•„ë˜ ì½”ë“œë¥¼ ì‹¤í–‰í•´ë³´ê¸°\n",
        "\n",
        "    - ë§í¬ ì ‘ì† > íŒŒì¼ > \"Driveì— ì‚¬ë³¸ ì €ì¥\" í´ë¦­ $\\to$ í¸ì§‘ ê¶Œí•œì´ ìƒê¹€\n",
        "\n",
        "    - ëŸ°íƒ€ì„ > ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½ > T4 GPU ì„ íƒí•˜ê¸°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07bc9bd4",
      "metadata": {
        "id": "07bc9bd4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import v2\n",
        "\n",
        "# =============================================================================\n",
        "# 1. ë°ì´í„° ì¤€ë¹„ (ì „ì²˜ë¦¬, ì¦ê°•, ë°ì´í„°ë¡œë”)\n",
        "# =============================================================================\n",
        "\n",
        "# 1-1. ì „ì²˜ë¦¬ ë° ë°ì´í„° ì¦ê°• ì •ì˜\n",
        "# í•™ìŠµ ë°ì´í„°ì—ëŠ” ì´ë¯¸ì§€ ì¦ê°•(Augmentation)ì„ í¬í•¨í•˜ì—¬ ëª¨ë¸ì˜ ì¼ë°˜í™” ì„±ëŠ¥ì„ ë†’ì…ë‹ˆë‹¤.\n",
        "transforms_train = v2.Compose(\n",
        "    [\n",
        "        v2.ToImage(),                          # PIL Imageë¥¼ PyTorch í…ì„œë¡œ ë³€í™˜\n",
        "        v2.RandomHorizontalFlip(),             # ë¬´ì‘ìœ„ ì¢Œìš° ë°˜ì „ (ì¦ê°•)\n",
        "        v2.RandomResizedCrop(size=28),         # ë¬´ì‘ìœ„ë¡œ ì˜ë¼ì„œ 28x28ë¡œ ë¦¬ì‚¬ì´ì¦ˆ (ì¦ê°•)\n",
        "        v2.RandomRotation(degrees=10),         # ë¬´ì‘ìœ„ íšŒì „ (ì¦ê°•)\n",
        "        v2.ToDtype(dtype=torch.float32, scale=True), # í”½ì…€ ê°’ì„ 0~1 ë²”ìœ„ì˜ float íƒ€ì…ìœ¼ë¡œ ìŠ¤ì¼€ì¼ë§\n",
        "        v2.Normalize(mean=[0.286], std=[0.353]), # í•™ìŠµ ë°ì´í„°ì˜ í‰ê· /í‘œì¤€í¸ì°¨ë¥¼ ì´ìš©í•´ í‘œì¤€í™” (Normalize)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# í…ŒìŠ¤íŠ¸/ê²€ì¦ ë°ì´í„°ì—ëŠ” ì¦ê°•ì„ ì œì™¸í•˜ê³  í•„ìˆ˜ì ì¸ ì „ì²˜ë¦¬ë§Œ ì ìš©í•©ë‹ˆë‹¤.\n",
        "transforms_test = v2.Compose(\n",
        "    [\n",
        "        v2.ToImage(),                          # PIL Imageë¥¼ PyTorch í…ì„œë¡œ ë³€í™˜\n",
        "        v2.ToDtype(dtype=torch.float32, scale=True), # í”½ì…€ ê°’ì„ 0~1 ë²”ìœ„ì˜ float íƒ€ì…ìœ¼ë¡œ ìŠ¤ì¼€ì¼ë§\n",
        "        v2.Normalize(mean=[0.286], std=[0.353]), # í‘œì¤€í™”\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 1-2. FashionMNIST ë°ì´í„°ì…‹ ë¡œë“œ\n",
        "train_dataset = datasets.FashionMNIST(\n",
        "    root='./fashion_mnist',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transforms_train,  # í•™ìŠµ ë°ì´í„°ì— ì¦ê°•/ì „ì²˜ë¦¬ ì ìš©\n",
        ")\n",
        "\n",
        "test_dataset_full = datasets.FashionMNIST(\n",
        "    root='./fashion_mnist',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transforms_test,   # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ëŠ” ì „ì²˜ë¦¬ë§Œ ì ìš©\n",
        ")\n",
        "\n",
        "# 1-3. í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì„ ê²€ì¦(Validation)ê³¼ ìµœì¢… í…ŒìŠ¤íŠ¸(Test)ë¡œ ë¶„í• \n",
        "# ë§Œ ê°œì˜ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤‘ 5000ê°œë¥¼ ê²€ì¦ìš©ìœ¼ë¡œ, ë‚˜ë¨¸ì§€ 5000ê°œë¥¼ ìµœì¢… í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ë¶„í• \n",
        "val_dataset, test_dataset = random_split(test_dataset_full, [5000, 5000])\n",
        "\n",
        "# 1-4. DataLoader ê°ì²´ ìƒì„±\n",
        "train_dataloader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=128,\n",
        "    shuffle=True,          # í•™ìŠµ ì‹œ ë°ì´í„° ìˆœì„œë¥¼ ì„ìŒ\n",
        "    drop_last=True         # ë§ˆì§€ë§‰ ë°°ì¹˜ë¥¼ ë²„ë ¤ ë°°ì¹˜ í¬ê¸°ë¥¼ ì¼ì •í•˜ê²Œ ìœ ì§€\n",
        ")\n",
        "val_dataloader = DataLoader(dataset=val_dataset, batch_size=32)\n",
        "test_dataloader = DataLoader(dataset=test_dataset, batch_size=32)\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# 2. CNN ëª¨ë¸ ì •ì˜\n",
        "# =============================================================================\n",
        "\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Conv1: 1ì±„ë„(Grayscale) ì…ë ¥ -> 32ì±„ë„ ì¶œë ¥. ì»¤ë„ 3x3, íŒ¨ë”© 1ë¡œ í¬ê¸° ìœ ì§€ (28x28 -> 28x28)\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, 1, 1)\n",
        "        # Conv2: 32ì±„ë„ ì…ë ¥ -> 64ì±„ë„ ì¶œë ¥. ì»¤ë„ 3x3, íŒ¨ë”© 1ë¡œ í¬ê¸° ìœ ì§€ (14x14 -> 14x14)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1, 1)\n",
        "        # MaxPool: 2x2 í’€ë§, ìŠ¤íŠ¸ë¼ì´ë“œ 2 (ë†’ì´/ë„ˆë¹„ 1/2 ì¶•ì†Œ)\n",
        "        self.maxpool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # í•™ìŠµ ì‹œ 20% í™•ë¥ ë¡œ ë‰´ëŸ° ë¹„í™œì„±í™” (ì˜¤ë²„í”¼íŒ… ë°©ì§€)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "        # ë‹¤ì°¨ì› í”¼ì²˜ë§µì„ 1ì°¨ì› ë²¡í„°ë¡œ í¼ì¹¨ (Linear ë ˆì´ì–´ ì…ë ¥ì„ ìœ„í•´ í•„ìš”)\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        # Linear1 ì…ë ¥ ì°¨ì›: 64 (ì±„ë„) * 7 * 7 (ìµœì¢… í”¼ì²˜ë§µ í¬ê¸°) = 3136\n",
        "        self.linear1 = nn.Linear(3136, 64)\n",
        "        # Linear2 ì¶œë ¥ ì°¨ì›: 10 (í´ë˜ìŠ¤ ê°œìˆ˜)\n",
        "        self.linear2 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # ì²« ë²ˆì§¸ Conv-ReLU-Pool ë¸”ë¡\n",
        "        x = F.relu(self.conv1(x)) # Conv2d í›„ í™œì„±í™” í•¨ìˆ˜ (í•¨ìˆ˜í˜• F.relu ì‚¬ìš©)\n",
        "        x = self.maxpool(x)       # Max Pooling (28x28 -> 14x14)\n",
        "\n",
        "        # ë‘ ë²ˆì§¸ Conv-ReLU-Pool ë¸”ë¡\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.maxpool(x)       # Max Pooling (14x14 -> 7x7)\n",
        "\n",
        "        # Dropout ì ìš© í›„ ë²¡í„°ë¡œ í¼ì¹˜ê¸°\n",
        "        x = self.dropout(x)\n",
        "        x = self.flatten(x)       # (N, 64, 7, 7) -> (N, 3136)\n",
        "\n",
        "        # ì™„ì „ ì—°ê²° ë ˆì´ì–´\n",
        "        x = F.relu(self.linear1(x))\n",
        "        output = self.linear2(x)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# 3. ëª¨ë¸, ì†ì‹¤ í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì € ì„¤ì •\n",
        "# =============================================================================\n",
        "\n",
        "model = CNNModel()\n",
        "\n",
        "# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸ ë° ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# ì†ì‹¤ í•¨ìˆ˜: ë‹¤ì¤‘ ë¶„ë¥˜ ë¬¸ì œì— ì í•©í•œ CrossEntropyLoss ì‚¬ìš©\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "# ì˜µí‹°ë§ˆì´ì €: Adam ì‚¬ìš©\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# 4. í‰ê°€ í•¨ìˆ˜ ì •ì˜\n",
        "# =============================================================================\n",
        "\n",
        "def evaluate(dataloader, model, loss_fn):\n",
        "    # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì „í™˜ (Dropout, BatchNorm ë“±ì´ ë¹„í™œì„±í™”ë¨)\n",
        "    model.eval()\n",
        "    losses = []\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # í‰ê°€ ì‹œì—ëŠ” ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°ì´ í•„ìš” ì—†ìœ¼ë¯€ë¡œ ê¸°ë¡ì„ ë” (ë©”ëª¨ë¦¬ ì ˆì•½)\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            inputs = batch[0].to(device)\n",
        "            labels = batch[1].to(device)\n",
        "\n",
        "            # 1. ì˜ˆì¸¡ê°’ ê³„ì‚°\n",
        "            preds = model(inputs)  # [ë°°ì¹˜ í¬ê¸°, í´ë˜ìŠ¤ ê°œìˆ˜]\n",
        "\n",
        "            # 2. Loss ê³„ì‚°\n",
        "            loss = loss_fn(preds, labels)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            # 3. ì •í™•ë„ ê³„ì‚°\n",
        "            # torch.argmax(dim=1)ë¡œ ê°€ì¥ ë†’ì€ ê°’ì˜ ì¸ë±ìŠ¤(ì˜ˆì¸¡ í´ë˜ìŠ¤)ë¥¼ ì¶”ì¶œ\n",
        "            pred_labels = torch.argmax(preds, dim=1)\n",
        "            # ì •ë‹µ ê°œìˆ˜ ëˆ„ì  (True: 1, False: 0ìœ¼ë¡œ ê°„ì£¼í•˜ì—¬ í•©ì‚°)\n",
        "            correct += (pred_labels == labels).sum().item()\n",
        "            total += len(preds)\n",
        "\n",
        "    # í‰ê·  Lossì™€ ì •í™•ë„ ê³„ì‚°\n",
        "    avg_loss = sum(losses) / len(losses)\n",
        "    acc = correct / total\n",
        "\n",
        "    return avg_loss, acc\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# 5. í•™ìŠµ ë£¨í”„ ì‹¤í–‰\n",
        "# =============================================================================\n",
        "\n",
        "epochs = 5\n",
        "step = 0\n",
        "print(f\"Training started on device: {device}\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # ëª¨ë¸ì„ í•™ìŠµ ëª¨ë“œë¡œ ì „í™˜\n",
        "    model.train()\n",
        "    for train_batch in train_dataloader:\n",
        "        inputs = train_batch[0].to(device)\n",
        "        labels = train_batch[1].to(device)\n",
        "\n",
        "        # 1. ìˆœì „íŒŒ (Forward Pass)\n",
        "        preds = model(inputs)\n",
        "        loss = loss_fn(preds, labels)\n",
        "\n",
        "        # 2. ì—­ì „íŒŒ (Backward Pass)\n",
        "        loss.backward()            # ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°\n",
        "        optimizer.step()           # íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸\n",
        "        optimizer.zero_grad()      # ê·¸ë˜ë””ì–¸íŠ¸ ì´ˆê¸°í™”\n",
        "\n",
        "        step += 1\n",
        "        if step % 100 == 0:\n",
        "            print(f'step {step}, train loss: {loss.item():.4f}')\n",
        "\n",
        "    # ì—í­ ì¢…ë£Œ í›„ ê²€ì¦ ë°ì´í„°ë¡œ ëª¨ë¸ í‰ê°€\n",
        "    val_loss, val_acc = evaluate(val_dataloader, model, loss_fn)\n",
        "    print(f'epoch {epoch+1}/{epochs}, val loss: {val_loss:.4f}, val acc: {val_acc:.4f}\\n')\n",
        "\n",
        "print('Training finished!')\n",
        "\n",
        "# =============================================================================\n",
        "# 6. ìµœì¢… í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ í‰ê°€\n",
        "# =============================================================================\n",
        "\n",
        "test_loss, test_acc = evaluate(test_dataloader, model, loss_fn)\n",
        "print(f\"\\n[Final Test Result] Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}